\documentclass[10pt]{article}

\usepackage{times,fullpage,graphicx,amsmath, subfigure}
\usepackage[pdfborder={0 0 0},colorlinks]{hyperref}
\hypersetup{citecolor=DeepPink4, linkcolor=DarkRed, urlcolor= blue}
\title{\bf atac-seq pipeline} 
\author{Amal Thomas}

%% For program names
\newcommand{\prog}[1]{\texttt{#1}}
\newcommand\tab[1][1cm]{\hspace*{#1}}

\begin{document}

\maketitle

\begin{center}
A computational pipeline for processing and analyzing atac-seq data
\end{center} 

%%\tableofcontents
%%\newpage
\section{Overview}
In our pipeline, we provide a handy work flow to process the atac-seq data and identify those regions with differential chromatin profile. The pipeline has mainly two parts:
\begin{itemize}
\item Pre-processing part: Here we process the input raw data and prepare it for the downstream analysis. The main steps include quality checks of the raw data, read alignment to the appropriate reference genome and subsequent filtering, peak calling and creating UCSC Track Hub. 
\item Post-processing part: Here we try to identify those chromosomal regions that show significant difference in the chromatin accessibility. 
\end{itemize}
Users are assumed to have prior experience with UNIX/Linux environment and common bioinformatics tools.

\section{Pre-processing}

\subsection{Mapping reads}
\paragraph{Input files:} The input to our pipeline is raw next generation sequencing data in the FASTQ format. The raw files from Sequence Read Archive (SRA), have to be decompressed and properly split to generate the right FASTQ files.
\paragraph{Quality check:} \prog{FastQC} provides an easy way to analyse the quality of raw sequencing data. This will give us a hint whether our data has any experimental error. One can employ the tool by the following command:
\begin{verbatim}
fastqc <read1.fastq> <read2.fastq> -o <outputdir>
\end{verbatim}
\paragraph{Removing adapters:} Sequencing adapters can be easily removed using  \prog{trimgalore} program. Typical command for paired end reads is:\\
\begin{verbatim}
trim_galore --paired   <read1.fastq>  <read2.fastq>  \
  --output_dir  <output directory>
\end{verbatim}
Optional arguments:\\
To remove low quality reads use --quality parameter:
\begin{verbatim}
--quality <cutoff>
\end{verbatim}
\paragraph{Mapping:}
The trimmed read are mapped to respective genome using \prog{bowtie2}. Since the minimum distance between two Tn5 binding sites are about 38bp, only fragment size greater than this is kept.
\begin{verbatim}
bowtie2  -X 2000 --fr --no-discordant --no-mixed \
--minins 38  -x <bowtie-index> -1 <read1_trimmed.fastq> \
-2 <read2_trimmed.fastq> -S <read_mapped.sam>
\end{verbatim}
\paragraph{Create sorted bam file:} The output of mapping is in sam format, which is human readable. The downside of sam format is the huge file size. We can use samtools to convert samfile into smaller and compressed format called bam.
\begin{verbatim}
samtools view -bS read_mapped.sam \
 |samtools sort - read_mapped.sorted.bam
\end{verbatim}
\section{Qualtiy controls}
\paragraph{Remove unwanted chromosome:} Here we keep only those reads that is mapped to standard chromosomes. Reads mapped to mitochondrial DNA are also filtered out.
\begin{verbatim}
samtools view -h read_mapped.sorted.bam \
|awk 'substr($0,1,1) == "@"|| (length($3)<=5 && \
$3!="chrM" && $3 != "*"){{print $0}}' \
|samtools view -bS - > read_mapped.sorted.chr.bam
\end{verbatim}
\paragraph{Remove duplicate reads:} PCR duplicated reads are removed using Picard Tools \prog{MarkDuplicates}
\begin{verbatim}
java -Xmx2g -jar MarkDuplicates.jar \
INPUT = read_mapped.sorted.chr.bam \
METRICS_FILE=read_mapped.markdup.metrics" \
OUTPUT=read_mapped.sorted.chr.nodup.bam" \
REMOVE_DUPLICATES=true \
ASSUME_SORTED=true
\end{verbatim}
\paragraph{Remove low quality mapped reads:} Reads with Phred quality scores less than 30 are filtered out using the command:
\begin{verbatim}
samtools view -b -h -q 30 read_mapped.sorted.chr.nodup.bam \
> read_mapped.sorted.chr.nodup.filt.bam
\end{verbatim}
The output bam file can be indexed using:
\begin{verbatim}
samtools index read_mapped.sorted.chr.nodup.filt.bam
\end{verbatim} 
\section{Peak Calling} For each read to represent the center of Tn5 binding site we shift the + strands by +4 bp, and all reads aligning to the – strand by −5 bp. Here for convinience we convert the bam file to bed format and do the shifting of cordinates.
\begin{verbatim}
bamToBed -i read_mapped.sorted.chr.nodup.filt.bam > temp.bed

samtools view  read_mapped.sorted.chr.nodup.filt.bam \
| awk 'BEGIN{OFS="\t"}{print $1,$9}' > insert.temp
paste temp.bed insert.temp | \
awk 'BEGIN{OFS="\t"}{split($4,name,"/");if(name[1]== $7 && $6 == "+" )\
{print $1,$2+4,$3,$4,$8,$6}  \
else if(name[1]== $7 && $6 == "-" ){print $1,$2,$3-5,$4,$8,$6} \
> read_mapped.sorted.chr.nodup.filt.shift.bed

rm $INPUT_FILE".temp.bed" $INPUT_FILE".insert.temp"
\end{verbatim}
Now we are ready to perform peak calling. For this we will use  peak caller called MACS2. The shifted bed file is provided us the input for the program.
\begin{verbatim}
macs2 callpeak --gsize hs \
	      -f BED \
         --treatment read_mapped.filt.sorted.chr.nodup.shift.bed  \
         --outdir peaks/ \
         --name read_mapped \
         --keep-dup all \
         --call-summits \
         --shift -100 --extsize 200 \
         --nomodel --nolambda \
         --verbose 3
\end{verbatim}
The --shift -100 parameter will move the reads toward 3' to 5' direction and --extsize parameter will extend the 3' end to make 200 bp reads. This will ensure that center of each reads correspond to the original Tn5 cutting sites. For {\em e.g.}
\textbf{Original reads:}
\begin{verse}
chr1\tab 500\tab 550\tab read1 \tab .\tab +\\
chr1\tab 700\tab 750\tab read2 \tab .\tab-
\end{verse}
\textbf{Applying --shift -100:}
\begin{verse}
chr1\tab 400\tab 450\tab read1\tab .\tab +\\
chr1\tab 800\tab 850\tab read2\tab .\tab -
\end{verse}
\textbf{Applying --extsize 200:}
\begin{verse}
chr1\tab 400\tab 600\tab read1\tab .\tab +\\
chr1\tab 650\tab 850\tab read2\tab .\tab -
\end{verse}
\paragraph{Remove blacklisted regions:} We have to remove some problematic regions (microsatellites, centromeres, telomeres etc.) from the identified peaks. Encode blacklisted regions can be downloaded from this \href{https://sites.google.com/site/anshulkundaje/projects/blacklists}{website}.
\section{Create track hub }
\end{document}